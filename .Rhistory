vial_code = character(),
box_code = character(),
box_position = character(),
duplicate = character(),
Mangrove = numeric(),
Manmade = numeric(),
Saltmarsh = numeric(),
edge_man = numeric(),
edge_mar = numeric(),
edge_l.mangrove = numeric(),
edge_l.marsh = numeric(),
land_water_ratio = numeric(),
mud = numeric(),
fetch_distance = numeric(),
site_type = character(),
biomass = numeric(),
mangrove_quartiles = factor(levels = c("Q1", "Q2", "Q3", "Q4")), # Add this column explicitly
stringsAsFactors = FALSE
)
# Iterate over unique species in the dataframe
for (species_name in unique(pared_data$species_code)) {
# Check if the species is in the defined parameters
if (species_name %in% species_params$species) {
# Use species-specific edge and buf
params <- species_params[species_params$species == species_name, ]
edge_val <- params$edge
buf_val <- params$buf
} else {
# Use default edge and buf for other species
edge_val <- 1
buf_val <- 200 # Default buffer value, adjust as needed
}
# Determine the habitat folder
hab_folder_idx <- which(species_params$species == species_name)
hab_folder_selected <- ifelse(length(hab_folder_idx) > 0, hab_folder[hab_folder_idx], "satscale")
# Construct the file name
habx <- if (hab_folder_selected == "satscale") {
paste("google2022_", "edge", edge_val, "_buf", buf_val, sep = "")
} else {
paste("combined_", "edge", edge_val, "_buf", buf_val, sep = "")
}
# Load habitat data
hab <- read.csv(file.path(
"C:/Users/hl51981/OneDrive - University of Georgia/Leavitt_Herbert/PFFW/Pt Fourchon Food Webs R Directory/landscape_species_scale/SP23/landscape_analysis/output",
hab_folder_selected,
paste0(habx, ".csv")
))
# Filter and join data
ytb_result <- unwrapped_samples %>%
left_join(hab[,c("site_date_key", "edge_l.mangrove", "land_water_ratio", "site_type", "edge_mar", "edge_man")], by = "site_date_key") %>%
subset(species_code == species_name) %>%
subset(sample_trip == trip)
ytb_result$mangrove_quartiles <- cut(ytb_result$edge_l.mangrove,
breaks = c(-Inf, 0.25, 0.5, 0.75, Inf),
labels = c("Q1", "Q2", "Q3", "Q4"),
right = FALSE) # right = FALSE ensures intervals are left-closed
# Append `result` to `all_data`
ytb_analyzed <- rbind(ytb_analyzed, ytb_result)
}
ytb_analyzed <- ytb_analyzed %>% merge(site_data, by = "site_date_key")
#Checks
ytb_analyzed %>% distinct(site_date_key)
# Example data
library(dplyr)
species <- c("PENSETS", "PALSP", "CALSAP", "MINLON", "CTEBOL")
# Ensure all species are included, even if not in counts
species_df <- data.frame(species_code = species)
# Merge with counts, filling in missing species with NA
filtered_data <- merge(species_df, counts, by = "species_code", all.x = TRUE)
# Replace NAs with zeros
filtered_data[is.na(filtered_data)] <- 0
# Calculate additional samples needed
needed_samples <- filtered_data
needed_samples[-1] <- pmax(5 - filtered_data[-1], 0)
# Display result
print(needed_samples)
# Define species-specific parameters
species_params <- data.frame(
species = c("PENSETS", "PALSP", "CALSAP", "MINLON", "CTEBOL"),
edge = c(1, 1, 1, 1, 1),
buf = c(300, 300, 150, 50,400 )
)
# Define other variables
trip <- "2305"
hab_folder <- c('satscale', 'satscale', 'satscale', "smallscale", "satscale")
analyzed <- data.frame()
# Iterate over unique species in the dataframe
for (species_name in unique(site_species_processed$species_code)) {
# Check if the species is in the defined parameters
if (species_name %in% species_params$species) {
# Use species-specific edge and buf
params <- species_params[species_params$species == species_name, ]
edge_val <- params$edge
buf_val <- params$buf
} else {
# Use default edge and buf for other species
edge_val <- 1
buf_val <- 200 # Default buffer value, adjust as needed
}
# Determine the habitat folder
hab_folder_idx <- which(species_params$species == species_name)
hab_folder_selected <- ifelse(length(hab_folder_idx) > 0, hab_folder[hab_folder_idx], "satscale")
# Construct the file name
habx <- if (hab_folder_selected == "satscale") {
paste("google2022_", "edge", edge_val, "_buf", buf_val, sep = "")
} else {
paste("combined_2022_", "edge", edge_val, "_buf", buf_val, sep = "")
}
# Load habitat data
hab <- read.csv(file.path(
"C:/Users/hl51981/OneDrive - University of Georgia/Leavitt_Herbert/PFFW/Pt Fourchon Food Webs R Directory/landscape_species_scale/SP23/landscape_analysis/output",
hab_folder_selected,
paste0(habx, ".csv")
))
# Filter and join data
result <- site_species_processed %>%
left_join(hab, by = "site_date_key") %>%
subset(species_code == species_name) %>%
subset(sample_trip == trip)
# Append `result` to `all_data`
analyzed <- rbind(analyzed, result)
}
analyzed <- analyzed %>% merge(site_data, by = "site_date_key")
# View the combined data
analyzed$mangrove_quartiles <- cut(analyzed$edge_l.mangrove,
breaks = c(-Inf, 0.25, 0.5, 0.75, Inf),
labels = c("Q1", "Q2", "Q3", "Q4"),
right = FALSE) # right = FALSE ensures intervals are left-closed
# Create a complete combination grid
all_combinations <- expand.grid(species_code = species_params$species,
mangrove_quartiles = c("Q1", "Q2", "Q3", "Q4"),
stringsAsFactors = FALSE)
observed_counts <- analyzed %>%
distinct(species_code, mangrove_quartiles, site_date_key) %>%
group_by(species_code, mangrove_quartiles) %>%
summarise(count = n(), .groups = "drop")
# Join and fill missing values with 0
counts <- all_combinations %>%
left_join(observed_counts, by = c("species_code", "mangrove_quartiles")) %>%
mutate(count = replace_na(count, 0)) %>%
pivot_wider(names_from = mangrove_quartiles, values_from = count)
counts <- analyzed %>%
distinct(species_code,mangrove_quartiles,site_date_key ) %>%
group_by(species_code, mangrove_quartiles) %>%
summarise(count = n(), .groups = "drop")%>%
pivot_wider(names_from = mangrove_quartiles, values_from = count, values_fill = 0)
# View the result
print(counts)
# Create a complete combination grid
all_combinations <- expand.grid(species_code = species_params$species,
mangrove_quartiles = c("Q1", "Q2", "Q3", "Q4"),
stringsAsFactors = FALSE)
observed_counts <- analyzed %>%
distinct(species_code, mangrove_quartiles, site_date_key) %>%
group_by(species_code, mangrove_quartiles) %>%
summarise(count = n(), .groups = "drop")
# Join and fill missing values with 0
counts <- all_combinations %>%
left_join(observed_counts, by = c("species_code", "mangrove_quartiles")) %>%
mutate(count = replace_na(count, 0)) %>%
pivot_wider(names_from = mangrove_quartiles, values_from = count)
# Define species-specific parameters
species_params <- data.frame(
species = c("PENSETS", "PALSP", "CALSAP", "MINLON", "CTEBOL"),
edge = c(1, 1, 1, 1, 1),
buf = c(300, 300, 150, 50,400 )
)
# Define other variables
trip <- "2305"
hab_folder <- c('satscale', 'satscale', 'satscale', "smallscale", "satscale")
analyzed <- data.frame()
# Iterate over unique species in the dataframe
for (species_name in unique(site_species_processed$species_code)) {
# Check if the species is in the defined parameters
if (species_name %in% species_params$species) {
# Use species-specific edge and buf
params <- species_params[species_params$species == species_name, ]
edge_val <- params$edge
buf_val <- params$buf
} else {
# Use default edge and buf for other species
edge_val <- 1
buf_val <- 200 # Default buffer value, adjust as needed
}
# Determine the habitat folder
hab_folder_idx <- which(species_params$species == species_name)
hab_folder_selected <- ifelse(length(hab_folder_idx) > 0, hab_folder[hab_folder_idx], "satscale")
# Construct the file name
habx <- if (hab_folder_selected == "satscale") {
paste("google2022_", "edge", edge_val, "_buf", buf_val, sep = "")
} else {
paste("combined_2022_", "edge", edge_val, "_buf", buf_val, sep = "")
}
# Load habitat data
hab <- read.csv(file.path(
"C:/Users/hl51981/OneDrive - University of Georgia/Leavitt_Herbert/PFFW/Pt Fourchon Food Webs R Directory/landscape_species_scale/SP23/landscape_analysis/output",
hab_folder_selected,
paste0(habx, ".csv")
))
# Filter and join data
result <- site_species_processed %>%
left_join(hab, by = "site_date_key") %>%
subset(species_code == species_name) %>%
subset(sample_trip == trip)
# Append `result` to `all_data`
analyzed <- rbind(analyzed, result)
}
analyzed <- analyzed %>% merge(site_data, by = "site_date_key")
# View the combined data
analyzed$mangrove_quartiles <- cut(analyzed$edge_l.mangrove,
breaks = c(-Inf, 0.25, 0.5, 0.75, Inf),
labels = c("Q1", "Q2", "Q3", "Q4"),
right = FALSE) # right = FALSE ensures intervals are left-closed
# Create a complete combination grid
all_combinations <- expand.grid(species_code = species_params$species,
mangrove_quartiles = c("Q1", "Q2", "Q3", "Q4"),
stringsAsFactors = FALSE)
observed_counts <- analyzed %>%
distinct(species_code, mangrove_quartiles, site_date_key) %>%
group_by(species_code, mangrove_quartiles) %>%
summarise(count = n(), .groups = "drop")
# Join and fill missing values with 0
counts <- all_combinations %>%
left_join(observed_counts, by = c("species_code", "mangrove_quartiles")) %>%
mutate(count = replace_na(count, 0)) %>%
pivot_wider(names_from = mangrove_quartiles, values_from = count)
# View the result
print(counts)
# Define species-specific parameters
species_params <- data.frame(
species = c("PENSETS", "PALSP", "CALSAP", "MINLON", "CTEBOL"),
edge = c(1, 1, 1, 1, 1),
buf = c(300, 300, 150, 50,400 )
)
ytb_analyzed <- data.frame(
site_date_key = character(),
species_code = character(),
sample_trip = integer(),
count = integer(),
tin_key = character(),
vial_code = character(),
box_code = character(),
box_position = character(),
duplicate = character(),
Mangrove = numeric(),
Manmade = numeric(),
Saltmarsh = numeric(),
edge_man = numeric(),
edge_mar = numeric(),
edge_l.mangrove = numeric(),
edge_l.marsh = numeric(),
land_water_ratio = numeric(),
mud = numeric(),
fetch_distance = numeric(),
site_type = character(),
biomass = numeric(),
mangrove_quartiles = factor(levels = c("Q1", "Q2", "Q3", "Q4")), # Add this column explicitly
stringsAsFactors = FALSE
)
# Iterate over unique species in the dataframe
for (species_name in unique(pared_data$species_code)) {
# Check if the species is in the defined parameters
if (species_name %in% species_params$species) {
# Use species-specific edge and buf
params <- species_params[species_params$species == species_name, ]
edge_val <- params$edge
buf_val <- params$buf
} else {
# Use default edge and buf for other species
edge_val <- 1
buf_val <- 200 # Default buffer value, adjust as needed
}
# Determine the habitat folder
hab_folder_idx <- which(species_params$species == species_name)
hab_folder_selected <- ifelse(length(hab_folder_idx) > 0, hab_folder[hab_folder_idx], "satscale")
# Construct the file name
habx <- if (hab_folder_selected == "satscale") {
paste("google2022_", "edge", edge_val, "_buf", buf_val, sep = "")
} else {
paste("combined_", "edge", edge_val, "_buf", buf_val, sep = "")
}
# Load habitat data
hab <- read.csv(file.path(
"C:/Users/hl51981/OneDrive - University of Georgia/Leavitt_Herbert/PFFW/Pt Fourchon Food Webs R Directory/landscape_species_scale/SP23/landscape_analysis/output",
hab_folder_selected,
paste0(habx, ".csv")
))
# Filter and join data
ytb_result <- unwrapped_samples %>%
left_join(hab[,c("site_date_key", "edge_l.mangrove", "land_water_ratio", "site_type", "edge_mar", "edge_man")], by = "site_date_key") %>%
subset(species_code == species_name) %>%
subset(sample_trip == trip)
ytb_result$mangrove_quartiles <- cut(ytb_result$edge_l.mangrove,
breaks = c(-Inf, 0.25, 0.5, 0.75, Inf),
labels = c("Q1", "Q2", "Q3", "Q4"),
right = FALSE) # right = FALSE ensures intervals are left-closed
# Append `result` to `all_data`
ytb_analyzed <- rbind(ytb_analyzed, ytb_result)
}
ytb_analyzed <- ytb_analyzed %>% merge(site_data, by = "site_date_key")
#Checks
ytb_analyzed %>% distinct(site_date_key)
# Example data
library(dplyr)
species <- c("PENSETS", "PALSP", "CALSAP", "MINLON", "CTEBOL")
# Ensure all species are included, even if not in counts
species_df <- data.frame(species_code = species)
# Merge with counts, filling in missing species with NA
filtered_data <- merge(species_df, counts, by = "species_code", all.x = TRUE)
# Replace NAs with zeros
filtered_data[is.na(filtered_data)] <- 0
# Calculate additional samples needed
needed_samples <- filtered_data
needed_samples[-1] <- pmax(5 - filtered_data[-1], 0)
# Display result
print(needed_samples)
selected_samples <- data.frame()
excluded_combinations<-data.frame()
library(raster)
crop20<-raster("C:/Users/hl51981/OneDrive - University of Georgia/Leavitt_Herbert/PFFW/Pt Fourchon Food Webs R Directory/raw_input/shapefiles/PtFou2020crop.tif")
# Specify the EPSG code for UTM Zone 15N (EPSG:32615)
# Define the target CRS
utm_crs <- CRS("+proj=utm +zone=15 +datum=WGS84 +units=m +no_defs")
# Reproject the raster
crop20_utm <- projectRaster(crop20, crs = utm_crs)
old_table <- subset(drop_sample_tracking, wrapping_inventory.tray_code %in% c("d5e5be06_2025-T4", "b19292a6_2025-T4")
)
for (species in needed_samples$species_code) {
for (mangrove_quantile in c("Q1", "Q2", "Q3", "Q4")) {
# Number of samples needed for this species and site type
needed <- needed_samples[needed_samples$species_code == species, mangrove_quantile]
print(paste("Processing", species, mangrove_quantile))
if (needed > 0) {
# Filter unprocessed samples for the current species and site type
available_samples <- ytb_analyzed[
ytb_analyzed$species_code == species &
ytb_analyzed$mangrove_quartiles == mangrove_quantile,
] %>% drop_na(grind_vial, biomass)
available_samples <- subset(available_samples, biomass > 0.02)
# Convert to sf and project to UTM
available_samples_sf <- st_as_sf(available_samples, coords = c("lon", "lat"), crs = 4326)
analyzed_sf <- st_as_sf(analyzed, coords = c("lon", "lat"), crs = 4326) %>% subset(species_code == species & mangrove_quartiles == mangrove_quantile)
available_samples_utm <- st_transform(available_samples_sf, crs = 32615)
analyzed_utm <- st_transform(analyzed_sf, crs = 32615)
if (nrow(available_samples_utm) <= needed) {
print(paste("need", needed, "but only", nrow(available_samples_utm), "available"))
available_samples_utm <- available_samples_utm %>% mutate(cluster = NA) %>% dplyr::select("site_date_key" , "species_code", "final_vial") %>% st_drop_geometry()
selected_samples <- bind_rows(selected_samples, available_samples_utm)
selected <- as.data.frame(selected_samples)
excluded_combinations <- bind_rows(
excluded_combinations,
selected[, c("site_date_key", "species_code")]
)
} else {
# Merge the available and analyzed points
merged_data <- bind_rows(
available_samples_utm %>% mutate(data_type = "available"),
analyzed_utm %>% mutate(data_type = "analyzed")
)
# Perform k-means clustering
set.seed(789)  # For reproducibility
n_clusters <- 5  # Always create 5 clusters
coordinates <- st_coordinates(merged_data)
kmeans_result <- kmeans(coordinates, centers = n_clusters, nstart = 5, iter.max = 30)
# Assign cluster labels
merged_data <- merged_data %>%
mutate(cluster = kmeans_result$cluster)
# Plot the data
# Define a custom color palette for clusters
num_clusters <- length(unique(merged_data$cluster))
colors <- rainbow(num_clusters)  # Generates distinct colors for each cluster
# Map colors to clusters
cluster_colors <- colors[as.numeric(as.factor(merged_data$cluster))]
merged_data_utm <- st_transform(merged_data, crs = 32615)
# Define custom pch mapping for 'available' and 'analyzed'
custom_pch <- c("available" = 21, "analyzed" = 22)  # 21 = filled circle, 22 = filled square
# Map pch values to the data_type column
pch_values <- custom_pch[merged_data$data_type]
plot(crop20_utm)
plot(
st_geometry(merged_data_utm),
col = "black",  # Custom colors for clusters
bg = cluster_colors,
pch = pch_values,  # Shapes for data_type
cex = 1,  # Increase point size
add = TRUE  # Overlay points on the map
)
# Add legends
# Create the legend with fixed pch values
legend(
"topright",
legend = names(custom_pch),         # Legend labels
pch = custom_pch,                   # Fixed pch values for each type
title = paste(species, mangrove_quantile, "needed:", needed),
bty = "n"                           # No box around the legend
)
legend(
"topright",
legend = unique(merged_data$data_type),
pch = pch_values,
title = paste(species, mangrove_quantile, "needed:", needed),
bty = "n"
)
legend(
"bottomleft",
legend = unique(merged_data$cluster),
col = colors[1:num_clusters],
pch = 16,
title = "Clusters",
bty = "n"
)
# Identify clusters containing analyzed points
analyzed_clusters <- merged_data %>%
filter(data_type == "analyzed") %>%
pull(cluster) %>%
unique()
# Remove clusters containing analyzed points
available_samples_utm <- merged_data %>%
filter(data_type == "available" & !cluster %in% analyzed_clusters)
# Randomly select clusters up to the needed number
remaining_clusters <- available_samples_utm %>%
pull(cluster) %>%
unique()
old_table_species <- old_table %>% subset(drop_processing.species_code == species )
priority_clusters <- available_samples_utm %>%
filter(site_date_key %in% old_table_species$site_date_key) %>%
pull(cluster) %>%
unique()
# Choose clusters, prioritizing those with priority vials
if (length(priority_clusters) >= needed) {
selected_clusters <- sample(priority_clusters, size = needed)
} else {
non_priority_clusters <- as.character(setdiff(remaining_clusters, priority_clusters), NULL)
str(non_priority_clusters)
additional_clusters <- sample(c(non_priority_clusters), size = needed - length(priority_clusters))
print(additional_clusters)
selected_clusters <- c(priority_clusters, additional_clusters)
}
# Commented out while troupbleshooting already-wrapped samples
# selected_clusters <- sample(remaining_clusters, size = min(needed, length(remaining_clusters)))
# Select one row from each selected cluster
#
# selected <- available_samples_utm %>%
# filter(cluster %in% selected_clusters) %>%
#  group_by(cluster) %>%
#  slice_sample(n = 1) %>%
#  ungroup()
# Join with priority vial list
available_samples_utm <- available_samples_utm %>%
mutate(priority = ifelse(site_date_key %in% old_table_species$site_date_key, TRUE, FALSE))
# Pick 1 vial per cluster, prioritizing vials from the priority list
selected <- available_samples_utm %>%
filter(cluster %in% selected_clusters) %>%
group_by(cluster) %>%
slice_max(order_by = priority, with_ties = TRUE) %>%  # prioritizes TRUE
slice_sample(n = 1) %>%
ungroup() %>%
st_drop_geometry() %>%
dplyr::select(c("site_date_key", "species_code", "final_vial"))
# Append to the selected samples list
selected_samples <- rbind(selected_samples, selected)
selected <- as.data.frame(selected)
excluded_combinations <- rbind(
excluded_combinations,
selected[, c("site_date_key", "species_code")]
)
}
}
}
}
######### TO TROUBLESHOOT: Seems to be overlap in the analyzed and available site for CALSAP Q1
# Ensure `selected_samples` contains the relevant rows and columns
simple_select <- selected_samples[, c("site_date_key", "species_code")] %>% st_drop_geometry()
# Find all rows with the same `site_date_key` and `species_code` as `selected_samples`
related_vials <- drop_sample_tracking %>%
semi_join(
simple_select,
by = c("site_date_key" = "site_date_key", "drop_processing.species_code" = "species_code")
) %>%
subset(grinding_inventory.duplicate == FALSE)
# Add the related vials to `selected_samples`
library(janitor)
need_to_wrap <- related_vials %>% dplyr::select("site_date_key", "drop_processing.species_code") %>% unique
wrapping_table_v2 <- need_to_wrap %>% left_join(drop_sample_tracking[c("site_date_key", "drop_processing.species_code", "grinding_inventory.box_code", "grinding_inventory.box_position", "final_vial","grinding_inventory.duplicate")]) %>% subset(grinding_inventory.duplicate == FALSE)  %>% arrange(drop_processing.species_code, site_date_key)
write.csv(wrapping_table_v2, "SP23/wrapping_table_250515.csv", row.names = FALSE)
write.csv(wrapping_table_v2, "C:/Users/hl51981/OneDrive - University of Georgia/Leavitt_Herbert/PFFW/Pt Fourchon Food Webs R Directory/isotope_workflow/sample_selection/selected samples/SP23/wrapping_table_250515.csv", row.names = FALSE)
setwd("C:/Users/hl51981/OneDrive - University of Georgia/Leavitt_Herbert/PFFW/Manuscripts/Global Change/Revision_repository")
setwd("C:/Users/hl51981/OneDrive - University of Georgia/Leavitt_Herbert/PFFW/Manuscripts/Global Change/Revision_repository")
nelson_species<-read.csv("raw_data/species_list.csv")
species_codex<-read.csv("final_alphia_codex_edited.csv")
species_codex<-read.csv("final_aphia_codex_edited.csv")
test<-species_codex %>% full_join(nelson_species, by = "Aphia_ID")
library(tidyverse)
nelson_species<-read.csv("raw_data/species_list.csv")
test<-species_codex %>% full_join(nelson_species, by = "Aphia_ID")
View(nelson_species)
View(species_codex)
test<-species_codex %>% full_join(nelson_species, by = "AphiaID")
species_codex<-read.csv("final_aphia_codex_edited.csv") %>% as.character(.$AphiaID)
species_codex
species_codex
species_codex$AphiaID<-as.character(.$AphiaID)
species_codex$AphiaID<-as.character(species_codex$AphiaID)
nelson_species<-read.csv("raw_data/species_list.csv")
species_codex<-read.csv("final_aphia_codex_edited.csv")
species_codex$AphiaID<-as.character(species_codex$AphiaID)
test<-species_codex %>% full_join(nelson_species, by = "AphiaID")
nelson_species<-read.csv("raw_data/species_list.csv")
species_codex<-read.csv("final_aphia_codex_edited.csv")
nelson_species$AphiaID<-as.character(nelson_species$AphiaID)
test<-species_codex %>% full_join(nelson_species, by = "AphiaID")
View(test)
